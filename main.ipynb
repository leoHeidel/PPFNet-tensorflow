{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gentle-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liable-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models = src.shapenet.get_shapenet_data(\"train\")\n",
    "model_path = train_models[np.random.randint(len(train_models))]\n",
    "cloud = src.shapenet.sample_points(model_path, nb=100000)\n",
    "extractor = src.dataset.PPFPatchExtractor(nb_patches=2044, nb_points=1024)\n",
    "ppf, M = extractor.make_example(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liable-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "class PPFNet:\n",
    "    def make_model(self):\n",
    "        inputs = keras.Input(shape=(None,None,10)) # (batch, patches, points_per_patches, ppf_features)\n",
    "        x = inputs \n",
    "        \n",
    "        #Patch pointNet\n",
    "        for units in self.point_net_units[:-1]:\n",
    "            x = keras.layers.Dense(units)(x)\n",
    "            if self.use_batch_norm:\n",
    "                x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.Activation(keras.activations.relu)(x)\n",
    "        x = keras.layers.Dense(self.point_net_units[-1])(x)\n",
    "        x = tf.reduce_max(x, axis=-2)# (batch, patches, patche_features)\n",
    "        local_features = x\n",
    "        \n",
    "        #Computing global features, nothing in the loop for orinigal implementation\n",
    "        for i,units in enumerate(self.global_units):\n",
    "            x = keras.layers.Dense(units)(x)\n",
    "            if i != len(self.global_units) -1:\n",
    "                if self.use_batch_norm:\n",
    "                    x = keras.layers.BatchNormalization()(x)\n",
    "                x = keras.layers.Activation(keras.activations.relu)(x)            \n",
    "        x = tf.reduce_max(x, axis=-2)# (batch, patches)\n",
    "        \n",
    "        #Combining features\n",
    "        x = tf.repeat(x[...,tf.newaxis,:], tf.shape(local_features)[-2], axis=-2)\n",
    "        x = tf.concat([local_features, x], axis=-1)\n",
    "        \n",
    "        #Computing combined features\n",
    "        for units in self.mlp_units[:-1]: \n",
    "            x = keras.layers.Dense(units)(x)\n",
    "            if self.use_batch_norm:\n",
    "                x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.Activation(keras.activations.relu)(x)\n",
    "        x = keras.layers.Dense(self.point_net_units[-1])(x)\n",
    "        \n",
    "        return keras.models.Model(inputs, x)\n",
    "    \n",
    "    def __init__(self, \n",
    "                 point_net_units=[32,32,32], \n",
    "                 mlp_units=[64,64], \n",
    "                 global_units=[],\n",
    "                 use_batch_norm=True,\n",
    "                ):\n",
    "        self.point_net_units = point_net_units\n",
    "        self.mlp_units = mlp_units\n",
    "        self.global_units = global_units\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        \n",
    "        self.model = self.make_model()\n",
    "        \n",
    "ppfnet = PPFNet()\n",
    "pred = ppfnet.model(ppf[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efficient-shift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2044, 32), dtype=float32, numpy=\n",
       "array([[[ 2.01860443e-02,  7.44291723e-01, -3.64723921e-01, ...,\n",
       "         -1.99749798e-01,  1.50939807e-01, -6.23417869e-02],\n",
       "        [ 2.26361752e-02,  7.63214111e-01, -4.45456684e-01, ...,\n",
       "         -2.61724353e-01,  1.39588580e-01, -8.60113651e-02],\n",
       "        [-5.05266190e-02,  6.76984310e-01, -4.56612110e-01, ...,\n",
       "         -1.68286577e-01,  1.07052416e-01,  1.33529305e-04],\n",
       "        ...,\n",
       "        [-3.28571051e-02,  7.36261725e-01, -4.44855630e-01, ...,\n",
       "         -2.20516697e-01,  1.02040432e-01, -4.55468893e-04],\n",
       "        [-4.38063890e-02,  7.00815022e-01, -4.66150403e-01, ...,\n",
       "         -2.08308220e-01,  5.46253063e-02, -4.52954769e-02],\n",
       "        [-8.95734057e-02,  6.93334103e-01, -3.63862991e-01, ...,\n",
       "         -1.96622208e-01,  9.99273136e-02, -2.80843042e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-cabinet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
